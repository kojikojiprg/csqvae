# dataset
name: "mnist"
n_labeled_samples: 6000
x_dim: 784  # 28 * 28
x_shape: [1, 28, 28]
patch_size: [7, 7]

# clustering
n_clusters: 10
param_q_init_cls: 1
temp_init_cls: 1.0
temp_decay_cls: 0.0001
temp_min_cls: 0.001

# quantization
book_size: 128
param_q_init: 10
temp_init: 1.0
temp_decay: 0.00001
temp_min: 0.001

# encoder-decoder
n_resblocks: 2
latent_dim: 64
latent_size: [7, 7]

# classification head
n_blocks_cls: 3
latent_dim_cls: 256
n_heads_cls: 16
dropout: 0.1

# diffusion
noise_steps: 1000
beta_start: 0.001
beta_end: 0.02
latent_dim_diffusion: 256
n_blocks_dit: 6
n_heads_dit: 16

loss:
  sqvae:
    lmd_x: 1
    lmd_klc: 1
    lmd_kld: 1
  diffusion:
    lmd_kld: 1
    lmd_ldt: 1
  csqvae:
    lmd_x: 1
    lmd_klc: 1
    lmd_kld: 1
    lmd_ldt: 1
    lmd_c_elbo: 1
    lmd_c_real: 100

optim:
  sqvae:
    epochs: 100
    batch_size: 128
    accumulate_grad_batches: 1
    lr: 0.001
    lr_min: 0.0001
    warmup_t: 10
    warmup_lr_init: 0.00001
  diffusion:
    epochs: 100
    batch_size: 128
    accumulate_grad_batches: 1
    lr: 0.0001
    lr_min: 0.00001
    warmup_t: 10
    warmup_lr_init: 0.00001
  csqvae:
    epochs: 1000
    batch_size: 128
    accumulate_grad_batches: 1
    lr: 0.0001
    lr_min: 0.00001
    warmup_t: 10
    warmup_lr_init: 0.000001

  num_workers: 4
